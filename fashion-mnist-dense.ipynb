{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.datasets import fashion_mnist\n\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\ntrain_images.shape","metadata":{"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 0s 0us/step\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"(60000, 28, 28)"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense,Flatten\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential([\n    Flatten(input_shape=(28,28)),\n    Dense(100, activation='relu'),\n    Dense(30, activation='relu'),\n    Dense(10, activation='softmax')\n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nflatten (Flatten)            (None, 784)               0         \n_________________________________________________________________\ndense (Dense)                (None, 100)               78500     \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                3030      \n_________________________________________________________________\ndense_2 (Dense)              (None, 10)                310       \n=================================================================\nTotal params: 81,840\nTrainable params: 81,840\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### categorical crossentropy를 적용하려면 target값은 반드시 ```one hot encoding``` 해야된다\none hot encoding 안할거면 sparse_categorical_crossentropy 사용","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import Accuracy\n\nmodel.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\ntrain_oh_labels = to_categorical(train_labels)\ntest_oh_labels = to_categorical(test_labels)\n\nhistory = model.fit(x=train_images, y=train_oh_labels, batch_size=32, epochs=20, verbose=1)\nprint(history.history['loss'])\nprint(history.history['accuracy'])","metadata":{"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Epoch 1/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 5.3910 - accuracy: 0.5273\nEpoch 2/20\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.7798 - accuracy: 0.6897\nEpoch 3/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.6975 - accuracy: 0.7199\nEpoch 4/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.6243 - accuracy: 0.7461\nEpoch 5/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.5564 - accuracy: 0.7820\nEpoch 6/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4774 - accuracy: 0.8287\nEpoch 7/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4325 - accuracy: 0.8462\nEpoch 8/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4084 - accuracy: 0.8559\nEpoch 9/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.4006 - accuracy: 0.8570\nEpoch 10/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3815 - accuracy: 0.8659\nEpoch 11/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3656 - accuracy: 0.8683\nEpoch 12/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3596 - accuracy: 0.8700\nEpoch 13/20\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.3545 - accuracy: 0.8712\nEpoch 14/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3465 - accuracy: 0.8766\nEpoch 15/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3466 - accuracy: 0.8762\nEpoch 16/20\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.3301 - accuracy: 0.8814\nEpoch 17/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3309 - accuracy: 0.8816\nEpoch 18/20\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.3242 - accuracy: 0.8828\nEpoch 19/20\n1875/1875 [==============================] - 3s 2ms/step - loss: 0.3240 - accuracy: 0.8831\nEpoch 20/20\n1875/1875 [==============================] - 4s 2ms/step - loss: 0.3248 - accuracy: 0.8845\n[1.863162636756897, 0.7683597803115845, 0.6867222189903259, 0.619346022605896, 0.5400114059448242, 0.47358912229537964, 0.4353772699832916, 0.4154248833656311, 0.39337074756622314, 0.3795388340950012, 0.3672425150871277, 0.3630615174770355, 0.3538219630718231, 0.35076653957366943, 0.3443518280982971, 0.3416208028793335, 0.33629757165908813, 0.33604753017425537, 0.3248320519924164, 0.33134737610816956]\n[0.6032333374023438, 0.6950666904449463, 0.7226666808128357, 0.7516166567802429, 0.7962833046913147, 0.8301166892051697, 0.8458499908447266, 0.8551666736602783, 0.8589666485786438, 0.8663333058357239, 0.868233323097229, 0.870283305644989, 0.8723499774932861, 0.8755499720573425, 0.8759333491325378, 0.8786333203315735, 0.8793833255767822, 0.8798333406448364, 0.8831833600997925, 0.8816333413124084]\n","output_type":"stream"}]},{"cell_type":"code","source":"pred_proba = model.predict(test_images)\nprint(pred_proba.shape)","metadata":{"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(10000, 10)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"전체 데이터셋을 predict할 경우 위의 cell처럼 n개의 28 * 28개의 데이터를 넣으면 되는데 하나의 이미지만 predict 시킬 때는 차원을 바꿔줘야한다\n\n```(10000,28,28)```형태로 3차원이어야 하는데 test_images[0]으로 하나의 이미지만 불러오면 ```(28,28)``` 이런식이기 때문\n\n```np.expand_dims```을 이용하여 차원을 늘려준다( []를 한겹 더 씌워준다고 생각하면됨)","metadata":{}},{"cell_type":"code","source":"test_images[0].shape","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(28, 28)"},"metadata":{}}]},{"cell_type":"markdown","source":"predict하여 각각의 class값에 대해 softmax 값을 구함\n\nnp.argmax로 최대값을 고른다\n\nnp.squeeze를 하면 predict를 할때 expand_dims로 차원을 늘린것을 다시 축소시켜준다","metadata":{}},{"cell_type":"code","source":"pred_proba = model.predict(np.expand_dims(test_images[0], axis=0))\nprint('softmax output : ', pred_proba)\npred = np.argmax(np.squeeze(pred_proba))\nprint('predicted class value : ', pred)","metadata":{"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"softmax output :  [[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n  7.2401721e-04 0.0000000e+00 4.6238527e-02 4.8881359e-12 9.5303744e-01]]\npredicted class value :  9\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(test_images, test_oh_labels, batch_size=64)","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"157/157 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.8581\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"[0.4430147111415863, 0.8580999970436096]"},"metadata":{}}]}]}